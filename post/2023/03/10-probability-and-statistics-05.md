# 《概率统计》 day 5

今天是读《概率统计》的逻辑第 5 天，学习条件概率。

梦开始的地方，先是黄申老师哪里看到，后来在刘润老师，再后来南添老师极力推荐，顺带还推荐了本书，这本书各种暗示概率好，概率妙，概率统计呱呱叫，整的跟古神低语一样。

叠加各种因素，最后决定看这本书。

最初就是被这个吸引。

条件概率 P(A | B) 是一个很棒的概念，它可以解释为学习知识 B 后 A 的概率，或者解释为得到信息 B 之后，消除一部分 A 的不确定性。

这个解释很和现实生活很贴合，我们做的大多数事情都是为了消除不确定性。

这个概念也解释了不同的人经历的 B 不一样，对 A 的理解也不一样，第一天的主观概率解释。

条件概率定义

$$
P(A | B) = \frac{P(A \cap B)}{P(B)}
$$

从 r 个红球，b 个篮球依次取出四个球，问四个球依次是红、蓝、红、蓝的概率。

按之前算法，样本空间是 S = P(r + b, 4)，红蓝红蓝的可能结果 M = C(r, 1)C(b, 1)C(r - 1, 1)C(b - 1, 1)

p = M / S

使用条件概率算法

$$
\begin{aligned}
P(A_1 \cap A_2 \cap ... \cap A_n) &= P(A_1) \\
&*P(A_2|A_1) \\
&*P(A_3 | A_1 \cap A_2) \\
&*... \\
&*P(A_n|A_1 \cap A_2 \cap ... \cap A_{n-1})
\end{aligned}
$$

$$
\begin{aligned}
P(R_1 \cap B_2 \cap R_3 \cap B4)
&=P(R_1)P(B_2|R_1)P(R_3|R_1 \cap B_2)P(R_4|R_1 \cap B_2 \cap R_3) \\
&=\frac{r}{r + b}\frac{b}{r + b - 1}\frac{r - 1}{r + b - 2}\frac{b - 1}{r + b - 3}
\end{aligned}
$$

好嘛，又多一种解法，这下更乱了。


P(A) 有时也叫边缘概率（marginal probability）据某不正经解释，这是因为 P(A) 是忽略条件之后的概率，想象一张二维表

||红盒子|蓝盒子|合计
|--|--|--|--|
长钉子|60|10|70|
短钉子|40|20|60|

忽略盒子之后的「合计」在最边上，所以叫边缘概率，似乎这样鬼扯也能圆的过来。

事件的边缘概率可以通过它的一个 partition 计算，B<sub>j</sub> 是样本空间的一个分割。这个词有叫分割的，有叫划分的，直接写原文了。

$$
P(A) = \sum_{j=1}^{k}P(B_j)P(A|B_j)
$$

红蓝盒子是样本空间的一个 partiton，概率都是 1/2 那么抽到长钉子的概率是

$$
\begin{aligned}
P(长钉子) &= \frac{1}{2} * \frac{60}{40 + 60} + \frac{1}{2} * \frac{10}{10 + 20} \\
&= \frac{7}{15}
\end{aligned}
$$

最后还有个有意思的题目，连续丢两颗骰子，丢出 7 或者 8 就停止，问丢出 7 的概率。

看完题目一脸懵逼，丢的次数都是不确定的，样本空间个数都没法算。

然后就看大佬开始操作，他先假设样本空间是以 7 或 8 结尾的序列，比如 {2, 7}, {10, 5, 8}，然后重新描述问题

+ 事件 A：实验结果是 7
+ 事件 B: 实验结果是 7 或者 8

所以

$$
p = P(A | B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)}{P(B)} = \frac{6 / 36}{(6 / 36) + (5 / 35)} = \frac{6}{11}
$$

好家伙，感觉都是破绽，又无懈可击，话说样本空间都变了，P(A) 难道不变么。

下次找朋友试试，要是它说的对，那赢面在一半以上，稳定坑一顿烧烤。

封面图：Twitter 心臓弱眞君 @xinzoruo