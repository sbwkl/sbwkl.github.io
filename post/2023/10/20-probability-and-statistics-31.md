# 《概率统计》 day 31

今天是读《概率统计》的逻辑第 31 天，学习充分统计量。

这个概念理解下来似乎是说对于一些统计推断，不需要完整的样本数据，只要某些统计就够了。

之前的例子中，参数 $\theta$ 的估计量只需要知道 $T =\sum_{i=1}^n X_i$，每个 $X_i$ 知不知道无所谓，(3, 1.5, 2.1) 也好 (2.4, 2.2, 2.0) 也罢，只要加起来等于 6.6 没区别。

形式化的定义：统计 $T=r(\vec{X})$ 如果条件概率
 $P(\vec{X} = \vec{x}|T=t, \theta)$ 与 $\theta$ 无关，那么统计 $T$ 是参数 $\theta$ 的充分统计量。

这么说有点抽象，如果似然函数可以分解为

$$
f_n(\vec{x}|\theta) = u(\vec{x}) v[r(\vec{x}), \theta]
$$

那么统计 $T=r(\vec{X})$ 就是充分统计量，$u$ 是 $\vec{x}$ 的函数和 $\theta$ 无关，$v$ 是统计 $T=r(\vec{X})$ 和 $\theta$ 的函数，和单个的 $x_i$ 无关。

比如 $X_i$ 是 $p$ 的伯努利分布，那么它的似然函数可以分解为 $u(\vec{x})=1$ 和 $v[r(\vec{x}), p] = p^{r(\vec{x})}(1-p)^{n-r(\vec{x})}$

$r(\vec{x})=\sum_{i=1}^n x_i$，所以 $T = \sum_{i=1}^n X_i$ 就是充分统计量。

这个比较好理解，来个反直觉的。假设 $X_i$ 是 $[0, \theta]$ 上的均匀分布，似然函数 $f(\vec{x}|\theta) = 1 /\theta^n$ 连 $x_i$ 都没有，那是不是意味着 $r(\vec{x})$ 可以是任何函数？

会有这种感觉是因为习惯性忽略 $f(x|\theta) = 0$ 的情况，其实它应该分解为 $f(\vec{x}|\theta) = \frac{1}{\theta^n}v(r(\vec{x}), \theta)$

$$
v(t, \theta) = \begin{cases}
    1 \ t \le \theta \\
    0 \ t \gt \theta
\end{cases}
$$

$r(\vec{x})=\max\{x_1, ..., x_n\}$ 所以 $T=\max\{X_1, ..., X_n\}$ 才是充分统计量。

有些统计推断一个 $T$ 不够，这时候似然函数分解为

$$
f_n(\vec{x}|\theta) = u(\vec{x}) v[r_1(\vec{x}), ..., r_k(\vec{x}), \theta]
$$

比如 $X_i$ 是伽马分布，它的似然函数

$f(\vec{x}|\alpha, \beta) = [\frac{\beta^\alpha}{\Gamma(\alpha)}]^n (r_1(\vec{x}))^{\alpha - 1} e^{-\beta r_2(\vec{x})}$

$r_1(\vec{x}) = \prod_{i=1}^n x_i$

$r_2(\vec{x}) = \sum_{i=1}^n x_i$

最离谱的情况需要 n 个 $r_i(\vec{x})$，等于全要，柯西分布就是这样的分布

$$
f(x|\theta) = \frac{1}{\pi [1+(x-\theta)^2]}
$$

这时候可以用顺序统计量，它把随机样本 $X_1, ..., X_n$ 从小到大排序，整理成另一份随机样本 $Y_1, ..., Y_n$，那这个 $Y_1, ..., Y_n$ 就叫顺序统计量。

顺序统计量一定是充分统计量（这不是废话么）。

与之相对，极小充分统计量需要的统计个数最小，它的定义是 $\vec{T} = (T_1, ..., T_k)$ 是充分统计量且 $\vec{T}$ 是其他充分统计量的函数 $\vec{T} = h(\vec{T^{'}})$。

光看这个定义也不知道怎么找极小充分统计量，不过话说回来，正常做实验谁会放着样本数据不要，闲得蛋疼只收集统计数据。

封面图：Twitter 心臓弱眞君 @xinzoruo